{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "import os, sys\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rc(\"font\", size=14)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just run one time\n",
    "#os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download data\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "path = os.path.join('data','wine_red.csv')\n",
    "response = rq.get(url)\n",
    "with open(path, 'wb') as f:\n",
    "    f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read and load data\n",
    "dataset = pd.read_csv(path, delimiter=';')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate label to data point\n",
    "X = dataset.loc[:, dataset.columns != 'quality']\n",
    "y = dataset.loc[:, dataset.columns == 'quality']\n",
    "\n",
    "#normalize by Min-Max scaling \n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "X = mm_scaler.fit_transform(X)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "#randomrize the data\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "#get the test set 10000 examples = 55.9 % of total dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.408329, random_state=0)\n",
    "test = np.hstack((X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the size of evaluate set is of : 2000\n",
      "the size of train set is of : 2898\n"
     ]
    }
   ],
   "source": [
    "print('the size of evaluate set is of :',y_test.shape[0])\n",
    "print('the size of train set is of :',y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First case. the size of train set is of : 100\n",
      "Third case. the size of train set is of : 1000\n",
      "Fourth case. the size of train set is of : 2883\n"
     ]
    }
   ],
   "source": [
    "#case 1 training dataset 100 examples\n",
    "X_train100, Y_train100 = shuffle(X_train,y_train, n_samples=100, random_state=0)\n",
    "print('First case. the size of train set is of :',X_train100.shape[0])\n",
    "\n",
    "#case 2 training dataset 1000 examples\n",
    "X_train1000, Y_train1000 = shuffle(X_train,y_train, n_samples=1000, random_state=2)\n",
    "print('Third case. the size of train set is of :',X_train1000.shape[0])\n",
    "\n",
    "#case 2 training dataset 2898 examples\n",
    "X_train2898, Y_train2898 = shuffle(X_train,y_train, n_samples=2883, random_state=3)\n",
    "print('Fourth case. the size of train set is of :',X_train2898.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction with coefficients\n",
    "def predict(rows, coefficients):\n",
    "    y_predicted = coefficients[0]\n",
    "    for index in range(len(rows)-1):\n",
    "        y_predicted += coefficients[index + 1] * rows[index]\n",
    "    return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate linear regression coefficients using stochastic gradient descent\n",
    "def sgd(train, l_rate, n_epoch):\n",
    "    loss = []\n",
    "    coef = [0.0 for i in range(len(train[0]))]# initialize weights in zero\n",
    "    for epoch in range(n_epoch):\n",
    "        for rows in train:\n",
    "            y_predicted = predict(rows, coef) # get predicted value\n",
    "            error = y_predicted - rows[-1] #calculate error\n",
    "            coef[0] = coef[0] - l_rate * error#b0(t+1) = b0(t) - learning_rate * error(t)\n",
    "            for i in range(len(rows)-1):\n",
    "                coef[i + 1] = coef[i + 1] - l_rate * error * rows[i]# b1(t+1) = b1(t) - learning_rate * error(t) * x1(t)\n",
    "            # print(l_rate, n_epoch, error)\n",
    "        loss.append(error)\n",
    "    return coef, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Algorithm With Stochastic Gradient Descent\n",
    "def linear_regression_sgd(train, test, l_rate, n_epoch):\n",
    "    predictions = list()\n",
    "    coef, loss = sgd(train, l_rate, n_epoch)# learning the weights in training data\n",
    "    for row in test:\n",
    "        yhat = predict(row, coef)# make p\n",
    "        predictions.append(yhat)\n",
    "    return(predictions), loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.65\n"
     ]
    }
   ],
   "source": [
    "# evaluate algorithm to fist case\n",
    "l_rate = 0.001\n",
    "n_epoch = 500\n",
    "train = np.hstack((X_train100,Y_train100))\n",
    "y_pred, loss = linear_regression_sgd(train, test, l_rate, n_epoch)\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.59\n"
     ]
    }
   ],
   "source": [
    "# evaluate algorithm to fist case\n",
    "l_rate = 0.01\n",
    "n_epoch = 500\n",
    "train = np.hstack((X_train1000,Y_train1000))\n",
    "y_pred, loss = linear_regression_sgd(train, test, l_rate, n_epoch)\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.58\n"
     ]
    }
   ],
   "source": [
    "# evaluate algorithm to fist case\n",
    "l_rate = 0.01\n",
    "n_epoch = 500\n",
    "train = np.hstack((X_train2898,Y_train2898))\n",
    "y_pred, loss = linear_regression_sgd(train, test, l_rate, n_epoch)\n",
    "print(\"Mean squared error: %.2f\"% mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "The above result shows how to aument the trainin data we will get less MSE. It is due to get more data, the model can adjust better to points. Happens the same to seconds task using sklearn LinearRegressor."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
